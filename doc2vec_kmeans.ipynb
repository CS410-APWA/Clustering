{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "import csv\n",
    "import gensim\n",
    "import logging\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import cycle\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Essays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_path = 'essays/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(essay_path)\n",
    "\n",
    "essays = {}\n",
    "for file in files:\n",
    "    # attempt to confidently guess encoding; otherwise, default to ISO-8859-1\n",
    "    encoding = \"ISO-8859-1\"\n",
    "    guess = chardet.detect(open(essay_path + file, \"rb\").read())\n",
    "    if (guess[\"confidence\"] >= 0.95):\n",
    "        encoding = guess[\"encoding\"]\n",
    "    \n",
    "    with open(essay_path + file, \"r\", encoding=encoding) as f:\n",
    "        essays[file] = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize + Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_essays = {label: gensim.utils.simple_preprocess(corpus, deacc=True, min_len=2, max_len=20) for (label, corpus) in essays.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "custom_stopwords = [\n",
    "        \"prison\",\n",
    "        \"jail\",\n",
    "        \"prisoner\",\n",
    "        \"also\",\n",
    "        \"said\",\n",
    "        \"would\",\n",
    "        \"could\",\n",
    "        \"should\",\n",
    "        \"first\",\n",
    "        \"like\",\n",
    "        \"get\",\n",
    "        \"going\",\n",
    "        \"thing\",\n",
    "        \"something\",\n",
    "        \"use\",\n",
    "        \"get\",\n",
    "        \"go\",\n",
    "        \"one\",\n",
    "        \"mr\",\n",
    "        \"many\",\n",
    "        \"much\",\n",
    "        \"see\",\n",
    "        \"take\",\n",
    "        \"another\",\n",
    "        \"aroud\",\n",
    "        \"away\",\n",
    "        \"back\",\n",
    "        \"even\",\n",
    "        \"every\",\n",
    "        \"guy\",\n",
    "        \"know\",\n",
    "        \"let\",\n",
    "        \"make\",\n",
    "        \"look\",\n",
    "        \"person\",\n",
    "        \"place\",\n",
    "        \"day\",\n",
    "        \"year\",\n",
    "        \"well\",\n",
    "        \"good\",\n",
    "        \"bad\",\n",
    "        \"with\",\n",
    "        \"without\",\n",
    "        \"may\",\n",
    "        \"new\",\n",
    "        \"two\",\n",
    "        \"want\",\n",
    "        \"people\",\n",
    "        \"within\",\n",
    "        \"upon\",\n",
    "        \"come\",\n",
    "        \"tilocblob\",\n",
    "        \"yyyyyy\",\n",
    "        \"way\",\n",
    "        \"around\",\n",
    "        \"high\",\n",
    "        \"inside\",\n",
    "        \"long\",\n",
    "        \"men\",\n",
    "        \"must\",\n",
    "        \"need\",\n",
    "        \"never\",\n",
    "        \"old\",\n",
    "        \"other\",\n",
    "        \"others\",\n",
    "        \"really\",\n",
    "        \"say\",\n",
    "        \"seem\",\n",
    "        \"still\",\n",
    "        \"try\",\n",
    "        \"become\",\n",
    "        \"allow\",\n",
    "        \"give\",\n",
    "        \"month\",\n",
    "        \"result\",\n",
    "        \"always\",\n",
    "        \"ask\",\n",
    "        \"begin\",\n",
    "        \"end\",\n",
    "        \"hour\",\n",
    "        \"man\",\n",
    "        \"woman\",\n",
    "        \"put\",\n",
    "        \"someone\",\n",
    "        \"start\",\n",
    "        \"next\",\n",
    "        \"act\",\n",
    "        \"create\",\n",
    "        \"yet\",\n",
    "        \"time\",\n",
    "        \"case\",\n",
    "        \"cell\",\n",
    "        \"work\",\n",
    "        \"call\",\n",
    "        \"world\",\n",
    "        \"tell\",\n",
    "        \"week\",\n",
    "        \"told\",\n",
    "        \"lot\",\n",
    "        \"change\",\n",
    "        \"self\",\n",
    "        \"since\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": nltk.corpus.wordnet.ADJ,\n",
    "                \"N\": nltk.corpus.wordnet.NOUN,\n",
    "                \"V\": nltk.corpus.wordnet.VERB,\n",
    "                \"R\": nltk.corpus.wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, nltk.corpus.wordnet.NOUN)\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "tokenized_essays = {label: [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in token_lst if (w not in string.punctuation and w not in english_stopwords and w not in custom_stopwords)] for (label, token_lst) in tokenized_essays.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_essays = {label: [w for w in token_lst if (w not in english_stopwords and w not in custom_stopwords)] for (label, token_lst) in tokenized_essays.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize w/ doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts processed:  1574\n"
     ]
    }
   ],
   "source": [
    "LabeledSentence1 = gensim.models.doc2vec.TaggedDocument\n",
    "all_content_train = []\n",
    "j=0\n",
    "for essay in tokenized_essays.values():\n",
    "    all_content_train.append(LabeledSentence1(essay, [j]))\n",
    "    j+=1\n",
    "    \n",
    "print(\"Number of texts processed: \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model = Doc2Vec(all_content_train, vector_size = 100, window = 10, min_count = 500, workers=7, dm = 1,alpha=0.025, min_alpha=0.001)\n",
    "d2v_model.train(all_content_train, total_examples=d2v_model.corpus_count, epochs=10, start_alpha=0.002, end_alpha=-0.016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_vectors = d2v_model.docvecs.vectors_docs\n",
    "vectorized_df = pd.DataFrame(essay_vectors)\n",
    "index_ref = vectorized_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature scaling through standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdsclr = StandardScaler()\n",
    "standardized_df = pd.DataFrame(stdsclr.fit_transform(vectorized_df.astype(float)), index=index_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "#reduced_df = pd.DataFrame(reduced, index=index_ref, columns = ['title', 'cluster', 'essay'])\n",
    "reduced_df = pd.DataFrame(pca.fit_transform(standardized_df), index=index_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide for output to visualize effectiveness of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_df.to_csv('new1.csv', sep='\\t', index=False, header=False)\n",
    "#pd.DataFrame(index_ref).to_csv('index.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering w/ k-means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 315 ms, sys: 66.7 ms, total: 381 ms\n",
      "Wall time: 175 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=12, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_clusters = 12\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters, init=\"k-means++\", max_iter=100)\n",
    "\n",
    "%time km.fit(reduced_df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essays per cluster / Theme(s) per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    517\n",
      "1     343\n",
      "7     254\n",
      "8     146\n",
      "3     108\n",
      "2      76\n",
      "6      32\n",
      "9      31\n",
      "10     25\n",
      "5      17\n",
      "0      16\n",
      "4       9\n",
      "Name: cluster, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "output = reduced_df\n",
    "output['cluster'] = km.labels_\n",
    "print(output['cluster'].value_counts())\n",
    "output['essay'] = tokenized_essays.values()\n",
    "output['title'] = tokenized_essays.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_index = {'Autobiographical, Paths to Prison': 'parent, damage, abuse, gang, alcohol, drug, neighborhood, hood, youth, pressure, fit, broken', \n",
    "                 'Family': 'family, abandonment, relation, visit, partner, mother, father, sibling, child, wife, husband, abuse, support', \n",
    "                 'Physical Conditions and Security': 'physical, condition, security, search, censorship, food, cold, hygiene, heat, misfunction, infestation, solitary, strip, search, fear, filth, violence, staff, abuse', \n",
    "                 'Prison Culture/Community/Society': 'violence, fear, staff, sexual, crime, outcasts, racial, cellmate, gay, LGBTQ, dehumanize, uniform, pecking, order, hierarchy, solid, dirty, skin, chomo',\n",
    "                 'Staff/prison Abuse of IP': 'abuse, sexual, torture, humiliation, racist, assault, antagonism, exacerbation, right, violation, food, hygiene, environment, legal, extraction, search, taunt',\n",
    "                 'Personal/Intern Change/Coping': 'survival, art, reading, writing, peace, faith, prayer, meditation, practice, community, activities, hobbies, cooking, remorse, motivation, education, discipline, coping, adjustment, responsibility, god, redemption, transformation',\n",
    "                 'Judicial Misconduct and Legal Remediation': 'judicial, incompetence, corruption, witness, evidence, excessive, political, jailhouse, lawyer, misconduct, unfair, pretender, plra, plea, grievance',\n",
    "                 'Political and Intellectual Labor among IP': 'activism, resistence, critique, race, class, change, policies, practices, write, organize, strike, solidarity',\n",
    "                 'Prison Industry/Prison as Business': 'labor, slave, condition, safety, health, profit, job, budget, tax, taxpayer, exploitation, corruption, mismanagement, nepotism',\n",
    "                 'Education, Re-entry, Other Programs': 'rehabilitation, entry, education, indifference, college, vocation',\n",
    "                 'Health Care': 'health, care, negligence, hostility, incompetence, indifference, death, injury, treatment, medication',\n",
    "                 'Social Alienation, Indifference, Hostility': 'public, misperception, identity, stigma'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import shutil\n",
    "\n",
    "src = \"/Users/inesayara/Desktop/senior_seminar/essays\"\n",
    "dst = \"/Users/inesayara/Desktop/clusters_1_0/cluster_\"\n",
    "\n",
    "#files = [i for i in os.listdir(src) if path.isfile(path.join(src, i))]\n",
    "#for f in files:\n",
    "#    shutil.copy(path.join(src, f), dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Random sample essays per cluster *****\n",
      "\n",
      "** Cluster 0: **\n",
      "\n",
      "Top terms #0 : ['abuse', 'believe', 'center', 'child', 'civil', 'commit', 'court', 'cp', 'crime', 'dr', 'education', 'fact', 'family', 'federal', 'group', 'help', 'include', 'individual', 'inmate', 'issue', 'justice', 'law', 'learn', 'level', 'life', 'nao', 'offender', 'official', 'parole', 'pay', 'pornography', 'problem', 'program', 'provide', 'release', 'right', 'security', 'sentence', 'sex', 'sexual', 'society', 'staff', 'state', 'system', 'texas', 'think', 'treatment', 'veteran', 'write', 'youth']\n",
      "\n",
      "Dominant theme(s): ['Autobiographical, Paths to Prison', 'Family', 'Physical Conditions and Security', 'Staff/prison Abuse of IP', 'Prison Culture/Community/Society']\n",
      "\n",
      "[('Prison Culture/Community/Society', 4), ('Staff/prison Abuse of IP', 4), ('Physical Conditions and Security', 3), ('Family', 3), ('Autobiographical, Paths to Prison', 3), ('Political and Intellectual Labor among IP', 1), ('Health Care', 1), ('Prison Industry/Prison as Business', 1), ('Judicial Misconduct and Legal Remediation', 1), ('Education, Re-entry, Other Programs', 1), ('Personal/Intern Change/Coping', 1)]\n",
      "\n",
      "Randomly selected essays: ['apw_12347457.txt', 'apw_12347462.txt', 'apw_12347734.txt', 'apw_12347822.txt', 'apw_12347683.txt', 'apw_12347795.txt', 'apw_12347492.txt', 'apw_12347402.txt', 'apw_12347203.txt', 'apw_12347539.txt']\n",
      "\n",
      "\n",
      "** Cluster 1: **\n",
      "\n",
      "Top terms #1 : ['believe', 'black', 'book', 'care', 'child', 'crime', 'death', 'enough', 'experience', 'eye', 'face', 'family', 'feel', 'find', 'friend', 'god', 'hand', 'help', 'home', 'hope', 'human', 'inmate', 'keep', 'last', 'learn', 'life', 'little', 'live', 'living', 'lose', 'love', 'mind', 'move', 'nothing', 'officer', 'part', 'problem', 'right', 'sentence', 'show', 'state', 'system', 'talk', 'think', 'thought', 'turn', 'understand', 'walk', 'word', 'write']\n",
      "\n",
      "Dominant theme(s): ['Health Care', 'Family', 'Prison Culture/Community/Society']\n",
      "\n",
      "[('Family', 3), ('Prison Culture/Community/Society', 2), ('Health Care', 2), ('Political and Intellectual Labor among IP', 1), ('Staff/prison Abuse of IP', 1), ('Personal/Intern Change/Coping', 1)]\n",
      "\n",
      "Randomly selected essays: ['apw_12343920.txt', 'apw_12352712.txt', 'apw_12352962.txt', 'apw_12344793.txt', 'apw_12341395.txt', 'apw_12350037.txt', 'apw_12345250.txt', 'apw_12349030.txt', 'apw_12345259.txt', 'apw_12345633.txt']\n",
      "\n",
      "\n",
      "** Cluster 2: **\n",
      "\n",
      "Top terms #2 : ['care', 'child', 'court', 'crime', 'death', 'door', 'drug', 'face', 'family', 'food', 'friend', 'guard', 'hand', 'head', 'help', 'home', 'house', 'inmate', 'job', 'later', 'law', 'left', 'letter', 'life', 'little', 'lock', 'money', 'mother', 'move', 'name', 'night', 'officer', 'phone', 'right', 'sentence', 'small', 'staff', 'state', 'system', 'talk', 'think', 'thought', 'three', 'turn', 'unit', 'walk', 'wall', 'watch', 'write', 'yard']\n",
      "\n",
      "Dominant theme(s): ['Health Care', 'Family', 'Prison Culture/Community/Society', 'Physical Conditions and Security', 'Staff/prison Abuse of IP', 'Judicial Misconduct and Legal Remediation']\n",
      "\n",
      "[('Family', 3), ('Judicial Misconduct and Legal Remediation', 2), ('Staff/prison Abuse of IP', 2), ('Physical Conditions and Security', 2), ('Prison Culture/Community/Society', 2), ('Health Care', 2), ('Political and Intellectual Labor among IP', 1), ('Personal/Intern Change/Coping', 1), ('Prison Industry/Prison as Business', 1), ('Autobiographical, Paths to Prison', 1)]\n",
      "\n",
      "Randomly selected essays: ['apw_12352836.txt', 'apw_12351577.txt', 'apw_12343805.txt', 'apw_12344038.txt', 'apw_185.txt', 'apw_12350921.txt', 'apw_12346959.txt', 'apw_12353618.txt', 'apw_12351973.txt', 'apw_12342290.txt']\n",
      "\n",
      "\n",
      "** Cluster 3: **\n",
      "\n",
      "Top terms #3 : ['america', 'american', 'behavior', 'black', 'cause', 'child', 'community', 'control', 'crime', 'criminal', 'drug', 'education', 'environment', 'experience', 'family', 'feel', 'group', 'help', 'human', 'incarcerate', 'incarceration', 'individual', 'inmate', 'law', 'lead', 'learn', 'life', 'live', 'mean', 'mind', 'order', 'part', 'personal', 'power', 'problem', 'process', 'program', 'reality', 'rehabilitation', 'right', 'sentence', 'social', 'society', 'state', 'system', 'think', 'thought', 'understand', 'violence', 'word']\n",
      "\n",
      "Dominant theme(s): ['Family', 'Personal/Intern Change/Coping', 'Prison Culture/Community/Society', 'Education, Re-entry, Other Programs', 'Staff/prison Abuse of IP']\n",
      "\n",
      "[('Prison Culture/Community/Society', 4), ('Family', 3), ('Staff/prison Abuse of IP', 2), ('Education, Re-entry, Other Programs', 2), ('Personal/Intern Change/Coping', 2), ('Physical Conditions and Security', 1), ('Judicial Misconduct and Legal Remediation', 1), ('Autobiographical, Paths to Prison', 1)]\n",
      "\n",
      "Randomly selected essays: ['apw_12345480.txt', 'apw_12346056.txt', 'apw_12344873.txt', 'apw_12352592.txt', 'apw_298.txt', 'apw_12341468.txt', 'apw_12349701.txt', 'apw_12352056.txt', 'apw_12343165.txt', 'apw_12347904.txt']\n",
      "\n",
      "\n",
      "** Cluster 4: **\n",
      "\n",
      "Top terms #4 : ['believe', 'charge', 'choice', 'cindy', 'doc', 'dope', 'drug', 'enough', 'everything', 'experience', 'face', 'feel', 'find', 'found', 'gang', 'guard', 'hand', 'help', 'hold', 'human', 'individual', 'inmate', 'job', 'judge', 'jury', 'keep', 'knew', 'learn', 'life', 'little', 'live', 'lose', 'point', 'prosecutor', 'right', 'room', 'sentence', 'side', 'special', 'stand', 'state', 'system', 'think', 'treat', 'trial', 'turn', 'unit', 'walk', 'white', 'write']\n",
      "\n",
      "Dominant theme(s): ['Autobiographical, Paths to Prison', 'Health Care']\n",
      "\n",
      "[('Health Care', 2), ('Autobiographical, Paths to Prison', 2), ('Political and Intellectual Labor among IP', 1), ('Personal/Intern Change/Coping', 1), ('Staff/prison Abuse of IP', 1), ('Prison Industry/Prison as Business', 1), ('Prison Culture/Community/Society', 1)]\n",
      "\n",
      "Randomly selected essays: ['apw_12347283.txt', 'apw_12347314.txt', 'apw_12347516.txt', 'apw_12347545.txt', 'apw_12347558.txt', 'apw_12347577.txt', 'apw_12347653.txt', 'apw_12347805.txt', 'apw_12347887.txt']\n",
      "\n",
      "\n",
      "** Cluster 5: **\n",
      "\n",
      "Top terms #5 : ['america', 'american', 'authority', 'behavior', 'black', 'community', 'condition', 'control', 'court', 'crime', 'criminal', 'death', 'experience', 'fact', 'force', 'form', 'gang', 'government', 'group', 'human', 'individual', 'justice', 'law', 'learn', 'life', 'male', 'mean', 'mind', 'order', 'political', 'power', 'principle', 'problem', 'process', 'program', 'public', 'right', 'sexual', 'social', 'society', 'state', 'system', 'term', 'theory', 'think', 'torture', 'violence', 'white', 'word', 'write']\n",
      "\n",
      "Dominant theme(s): ['Personal/Intern Change/Coping', 'Physical Conditions and Security', 'Prison Culture/Community/Society', 'Judicial Misconduct and Legal Remediation', 'Staff/prison Abuse of IP']\n",
      "\n",
      "[('Prison Culture/Community/Society', 6), ('Staff/prison Abuse of IP', 3), ('Judicial Misconduct and Legal Remediation', 2), ('Physical Conditions and Security', 2), ('Personal/Intern Change/Coping', 2), ('Political and Intellectual Labor among IP', 1), ('Social Alienation, Indifference, Hostility', 1), ('Autobiographical, Paths to Prison', 1), ('Health Care', 1), ('Prison Industry/Prison as Business', 1)]\n",
      "\n",
      "Randomly selected essays: ['apw_12352519.txt', 'apw_12342515.txt', 'apw_12345786.txt', 'apw_12345804.txt', 'apw_12351849.txt', 'apw_12351830.txt', 'apw_12345834.txt', 'apw_12342180.txt', 'apw_12351839.txt', 'apw_12352530.txt']\n",
      "\n",
      "\n",
      "** Cluster 6: **\n",
      "\n",
      "Top terms #6 : ['action', 'american', 'board', 'child', 'convict', 'conviction', 'cost', 'court', 'crime', 'criminal', 'death', 'drug', 'evidence', 'facility', 'family', 'federal', 'government', 'however', 'incarcerate', 'incarceration', 'inmate', 'issue', 'judge', 'justice', 'law', 'life', 'louisiana', 'number', 'offender', 'official', 'order', 'parole', 'policy', 'population', 'process', 'program', 'prosecutor', 'provide', 'public', 'rate', 'release', 'right', 'rule', 'sentence', 'serve', 'society', 'state', 'system', 'united', 'violent']\n",
      "\n",
      "Dominant theme(s): ['Staff/prison Abuse of IP', 'Family', 'Prison Culture/Community/Society', 'Judicial Misconduct and Legal Remediation']\n",
      "\n",
      "[('Judicial Misconduct and Legal Remediation', 2), ('Prison Culture/Community/Society', 2), ('Family', 2), ('Staff/prison Abuse of IP', 2), ('Social Alienation, Indifference, Hostility', 1), ('Autobiographical, Paths to Prison', 1), ('Health Care', 1)]\n",
      "\n",
      "Randomly selected essays: ['apw_12351292.txt', 'apw_12345218.txt', 'apw_12349215.txt', 'apw_12350025.txt', 'apw_12353056.txt', 'apw_12344096.txt', 'apw_12341407.txt', 'apw_12345642.txt', 'apw_12341398.txt', 'apw_12354034.txt']\n",
      "\n",
      "\n",
      "** Cluster 7: **\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms #7 : ['american', 'believe', 'black', 'board', 'california', 'community', 'condition', 'convict', 'correction', 'court', 'crime', 'criminal', 'death', 'department', 'drug', 'fact', 'family', 'federal', 'force', 'government', 'human', 'incarcerate', 'incarceration', 'individual', 'inmate', 'issue', 'justice', 'law', 'life', 'murder', 'offender', 'officer', 'parole', 'population', 'problem', 'program', 'provide', 'public', 'punishment', 'rehabilitation', 'release', 'right', 'sentence', 'serve', 'society', 'staff', 'state', 'system', 'term', 'united']\n",
      "\n",
      "Dominant theme(s): ['Physical Conditions and Security', 'Prison Culture/Community/Society']\n",
      "\n",
      "[('Prison Culture/Community/Society', 3), ('Physical Conditions and Security', 2), ('Staff/prison Abuse of IP', 1), ('Education, Re-entry, Other Programs', 1), ('Social Alienation, Indifference, Hostility', 1), ('Judicial Misconduct and Legal Remediation', 1), ('Family', 1), ('Autobiographical, Paths to Prison', 1), ('Health Care', 1), ('Prison Industry/Prison as Business', 1), ('Personal/Intern Change/Coping', 1)]\n",
      "\n",
      "Randomly selected essays: ['apw_12346863.txt', 'apw_12351882.txt', 'apw_12347028.txt', 'apw_12352659.txt', 'apw_12344622.txt', 'apw_12341428.txt', 'apw_12346079.txt', 'apw_12345011.txt', 'apw_12342697.txt', 'apw_12344717.txt']\n",
      "\n",
      "\n",
      "** Cluster 8: **\n",
      "\n",
      "Top terms #8 : ['california', 'care', 'charge', 'child', 'convict', 'correction', 'cost', 'court', 'crime', 'criminal', 'death', 'department', 'drug', 'facility', 'family', 'federal', 'find', 'guard', 'help', 'home', 'house', 'inmate', 'issue', 'job', 'justice', 'law', 'life', 'medical', 'money', 'offender', 'officer', 'order', 'parole', 'pay', 'problem', 'program', 'public', 'receive', 'release', 'right', 'sentence', 'serve', 'sex', 'staff', 'state', 'system', 'think', 'unit', 'visit', 'write']\n",
      "\n",
      "Dominant theme(s): ['Health Care', 'Family', 'Prison Culture/Community/Society', 'Judicial Misconduct and Legal Remediation', 'Prison Industry/Prison as Business', 'Staff/prison Abuse of IP']\n",
      "\n",
      "[('Prison Culture/Community/Society', 4), ('Family', 3), ('Staff/prison Abuse of IP', 2), ('Prison Industry/Prison as Business', 2), ('Judicial Misconduct and Legal Remediation', 2), ('Health Care', 2), ('Political and Intellectual Labor among IP', 1), ('Personal/Intern Change/Coping', 1), ('Physical Conditions and Security', 1), ('Social Alienation, Indifference, Hostility', 1), ('Autobiographical, Paths to Prison', 1)]\n",
      "\n",
      "Randomly selected essays: ['apw_12344319.txt', 'apw_12351618.txt', 'apw_12349159.txt', 'apw_12341592.txt', 'apw_12347014.txt', 'apw_12343408.txt', 'apw_12347776.txt', 'apw_12344658.txt', 'apw_12352846.txt', 'apw_12345190.txt']\n",
      "\n",
      "\n",
      "** Cluster 9: **\n",
      "\n",
      "Top terms #9 : ['behind', 'black', 'door', 'eye', 'face', 'family', 'father', 'fear', 'feel', 'felt', 'find', 'found', 'friend', 'guard', 'hand', 'head', 'help', 'home', 'keep', 'knew', 'learn', 'left', 'life', 'little', 'live', 'lock', 'love', 'mind', 'mother', 'move', 'night', 'open', 'page', 'right', 'room', 'school', 'small', 'talk', 'think', 'thought', 'three', 'turn', 'visit', 'wait', 'walk', 'wall', 'watch', 'word', 'write', 'yard']\n",
      "\n",
      "Dominant theme(s): ['Family']\n",
      "\n",
      "[('Family', 4), ('Political and Intellectual Labor among IP', 1), ('Staff/prison Abuse of IP', 1), ('Prison Culture/Community/Society', 1), ('Physical Conditions and Security', 1)]\n",
      "\n",
      "Randomly selected essays: ['apw_12345957.txt', 'apw_12346715.txt', 'apw_12341322.txt', 'apw_12345731.txt', 'apw_12353426.txt', 'apw_12348926.txt', 'apw_12345156.txt', 'apw_12347386.txt', 'apw_12346989.txt', 'apw_12345919.txt']\n",
      "\n",
      "\n",
      "** Cluster 10: **\n",
      "\n",
      "Top terms #10 : ['able', 'action', 'appear', 'body', 'consciousness', 'consider', 'control', 'course', 'different', 'emotional', 'everything', 'exist', 'existence', 'experience', 'feel', 'goal', 'help', 'human', 'keep', 'learn', 'life', 'light', 'little', 'mean', 'member', 'mind', 'move', 'order', 'outside', 'part', 'particle', 'past', 'personal', 'plan', 'power', 'process', 'program', 'reflection', 'release', 'right', 'sense', 'social', 'society', 'state', 'story', 'system', 'think', 'understand', 'word', 'write']\n",
      "\n",
      "Dominant theme(s): ['Staff/prison Abuse of IP', 'Prison Culture/Community/Society']\n",
      "\n",
      "[('Prison Culture/Community/Society', 2), ('Staff/prison Abuse of IP', 2), ('Political and Intellectual Labor among IP', 1), ('Family', 1)]\n",
      "\n",
      "Randomly selected essays: ['apw_12345572.txt', 'apw_12342923.txt', 'apw_12343056.txt', 'apw_12344818.txt', 'apw_12343092.txt', 'apw_12342547.txt', 'apw_12342628.txt', 'apw_12351703.txt', 'apw_12351437.txt', 'apw_12349225.txt']\n",
      "\n",
      "\n",
      "** Cluster 11: **\n",
      "\n",
      "Top terms #11 : ['black', 'book', 'care', 'correction', 'correctional', 'court', 'crime', 'criminal', 'death', 'department', 'drug', 'fact', 'family', 'feel', 'find', 'guard', 'help', 'human', 'inmate', 'job', 'justice', 'keep', 'law', 'learn', 'life', 'live', 'love', 'mean', 'mind', 'money', 'nothing', 'officer', 'parole', 'problem', 'program', 'public', 'release', 'right', 'rule', 'sentence', 'serve', 'society', 'staff', 'state', 'system', 'think', 'thought', 'unit', 'word', 'write']\n",
      "\n",
      "Dominant theme(s): ['Health Care', 'Prison Culture/Community/Society']\n",
      "\n",
      "[('Prison Culture/Community/Society', 3), ('Health Care', 2), ('Political and Intellectual Labor among IP', 1), ('Personal/Intern Change/Coping', 1), ('Physical Conditions and Security', 1), ('Staff/prison Abuse of IP', 1), ('Social Alienation, Indifference, Hostility', 1), ('Judicial Misconduct and Legal Remediation', 1), ('Prison Industry/Prison as Business', 1), ('Family', 1), ('Autobiographical, Paths to Prison', 1)]\n",
      "\n",
      "Randomly selected essays: ['apw_12346666.txt', 'apw_12351819.txt', 'apw_12343249.txt', 'apw_12346780.txt', 'apw_12343289.txt', 'apw_12341431.txt', 'apw_12351090.txt', 'apw_12350239.txt', 'apw_12344496.txt', 'apw_12346942.txt']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "\n",
    "essays_per_cluster = {}\n",
    "for i in range(num_clusters):\n",
    "    essays_per_cluster[i] = []\n",
    "    #print(\"Cluster %d titles:\" % i, end='')\n",
    "    for title in output[output.cluster == i]['title'].values.tolist():\n",
    "        #print(' %s,' % title, end='')\n",
    "        essays_per_cluster[i].append(title)\n",
    "        \n",
    "print(\"***** Random sample essays per cluster *****\")\n",
    "print()\n",
    "\n",
    "terms_per_essays = {}\n",
    "themes_per_essays = {}\n",
    "for i in range(num_clusters):\n",
    "    ten = []\n",
    "    if len(essays_per_cluster[i]) < 10:\n",
    "        ten = essays_per_cluster[i]\n",
    "    else:\n",
    "        while len(ten) < 10:\n",
    "            essay = random.choice(essays_per_cluster[i])\n",
    "            if essay not in ten:\n",
    "                ten.append(essay)\n",
    "\n",
    "    print(\"** Cluster %d: **\" % i)\n",
    "    print()\n",
    "    context = [' '.join(tokens) for tokens in list(output[output.cluster == i].essay)]\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=50)\n",
    "    tfidf_vectorizer.fit(context)\n",
    "    \n",
    "    #terms_per_essays[i] = [term for term in tfidf_vectorizer.get_feature_names() if term not in english_stopwords + custom_stopwords]\n",
    "    terms_per_essays[i] = [term for term in tfidf_vectorizer.get_feature_names()]\n",
    "    \n",
    "    print(\"Top terms #{} : {}\".format(i, terms_per_essays[i]))\n",
    "    print()\n",
    "    \n",
    "    themes_per_essays[i] = set()\n",
    "    theme_term_count = {}\n",
    "    for term in terms_per_essays[i]:\n",
    "        for key, value in theme_index.items():\n",
    "            if term in value:\n",
    "                if key in theme_term_count:\n",
    "                    theme_term_count[key] += 1\n",
    "                else:\n",
    "                    theme_term_count[key] = 1\n",
    "                themes_per_essays[i].add(key)\n",
    "    \n",
    "    themes_per_essays[i] = [theme for theme, count in theme_term_count.items() if count > 1]\n",
    "    print(\"Dominant theme(s): {}\".format(themes_per_essays[i]))\n",
    "    print()\n",
    "    print(sorted(theme_term_count.items(), key=lambda x : x[1])[::-1])\n",
    "    \n",
    "    print()\n",
    "    print(\"Randomly selected essays:\", ten)\n",
    "    files = [i for i in os.listdir(src) if i in ten and path.isfile(path.join(src, i))]\n",
    "    for f in files:\n",
    "        shutil.copy(path.join(src, f), dst + str(i))\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model/Load from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(km,'doc_cluster.pkl')\n",
    "\n",
    "#km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize cluster (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import random\n",
    "\n",
    "#%matplotlib inline\n",
    "#plt.figure\n",
    "\n",
    "#cluster_colors = []\n",
    "#for i in range(num_clusters):\n",
    "#    r = lambda: random.randint(0,255)\n",
    "#    cluster_colors.append('#%02X%02X%02X' % (r(),r(),r()))\n",
    "\n",
    "#color = [i for i in cluster_colors]\n",
    "#plt.scatter(datapoint[:, 0], datapoint[:, 1])\n",
    "#centroids = kmeans_model.cluster_centers_\n",
    "#centroidpoint = pca.transform(centroids)\n",
    "#plt.scatter(centroidpoint[:, 0], centroidpoint[:, 1], marker=\"^\", s=150, c=\"#000000\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
