{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import chardet\n",
    "import csv\n",
    "import gensim\n",
    "import logging\n",
    "import nltk\n",
    "import os\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import cycle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Essays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.dirname(os.path.realpath('__file__'))\n",
    "essay_path = root + '/../essays/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(essay_path)\n",
    "\n",
    "essays = {}\n",
    "for file in files:\n",
    "    # attempt to confidently guess encoding; otherwise, default to ISO-8859-1\n",
    "    encoding = \"ISO-8859-1\"\n",
    "    guess = chardet.detect(open(essay_path + file, \"rb\").read())\n",
    "    if (guess[\"confidence\"] >= 0.95):\n",
    "        encoding = guess[\"encoding\"]\n",
    "    \n",
    "    with open(essay_path + file, \"r\", encoding=encoding) as f:\n",
    "        essays[file] = f.read()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_mapping = [ (\"broken home\", \"brokenhome\"), (\"fit in\", \"fitin\"), (\"home boys\", \"homeboys\"),\n",
    "(\"crime partners\", \"crimepartners\"), (\"road dogs\", \"roaddogs\"), (\"step father\", \"stepfather\"),\n",
    "(\"old lady\", \"oldlady\"), (\"strip search\", \"stripsearch\"), (\"pecking order\", \"peckingorder\"),\n",
    "(\"solid crime\", \"solidcrime\"), (\"dirty crime\", \"dirtycrime\"), (\"skin crime\", \"skincrime\"),\n",
    "(\"solid prisoner\", \"solidprisoner\"), (\"dick sucker\", \"dicksucker\"), (\"cock sucker\", \"cocksucker\"),\n",
    "(\"shot caller\", \"shotcaller\"), (\"butt pirate\", \"buttpirate\"), (\"falsely accuse\", \"falselyaccuse\"),\n",
    "(\"born again\", \"bornagain\"), (\"good guy\", \"goodguy\"), (\"habeas corpus\", \"habeascorpus\"),\n",
    "(\"time barred\", \"timebarred\"), (\"successive petitions\", \"successivepetitions\"), (\"hunger strike\", \"hungerstrike\"),\n",
    "(\"1983 lawsuits\", \"1983lawsuits\"), (\"civil rights complaints\", \"civilrightscomplaints\"), (\"tax payers\", \"taxpayers\"),\n",
    "(\"private prisons\", \"privateprisons\"), (\"prison-industrial complex\", \"prison-industrialcomplex\"), (\"make money off of us\", \"makemoneyoffofus\"),\n",
    "(\"higher education\", \"highereducation\"), (\"correspondence courses\", \"correspondencecourses\"), (\"self help\", \"selfhelp\"),\n",
    "(\"mental health\", \"mentalhealth\"), (\"psych meds\", \"psychmeds\"), (\"kehea meds\", \"keheameds\"), (\"deliberate indifference\", \"deliberateindifference\") ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize + Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_essays = {label: gensim.utils.simple_preprocess(corpus, deacc=True, min_len=2, max_len=20) for (label, corpus) in essays.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": nltk.corpus.wordnet.ADJ,\n",
    "                \"N\": nltk.corpus.wordnet.NOUN,\n",
    "                \"V\": nltk.corpus.wordnet.VERB,\n",
    "                \"R\": nltk.corpus.wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, nltk.corpus.wordnet.NOUN)\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "tokenized_essays = {label: [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in token_lst if w not in string.punctuation] for (label, token_lst) in tokenized_essays.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = nltk.corpus.stopwords.words('english')\n",
    "custom_stopwords = open(\"custom_stopwords.txt\", \"r\").read().splitlines()\n",
    "tokenized_essays = {label: [w for w in token_lst if (w not in english_stopwords and w not in custom_stopwords)] for (label, token_lst) in tokenized_essays.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not currently linked to tokenized_essays\n",
    "import re\n",
    "lst = list(tokenized_essays.values())\n",
    "for i in range(len(lst)):\n",
    "    essay = ' '.join(lst[i])\n",
    "    for k, v in compound_mapping:\n",
    "        essay = re.sub(k, v, essay, flags=re.IGNORECASE) # replaces spaced words with their compounded versions, ignoring case\n",
    "    lst[i] = essay.split(' ')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize w/ doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(tokenized_essays.values())]\n",
    "d2v_model = Doc2Vec(documents, vector_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_df = pd.DataFrame(d2v_model.docvecs.vectors_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature scaling through standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdsclr = StandardScaler()\n",
    "standardized_df = pd.DataFrame(stdsclr.fit_transform(vectorized_df.astype(float)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle component analysis for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # only need this for visualization of vectors presumably\n",
    "# pca = PCA(n_components=3)\n",
    "# reduced_df = pd.DataFrame(pca.fit_transform(standardized_df))\n",
    "# reduced_df.to_csv('vectors.csv', sep='\\t', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering w/ k-means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 7\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters, init=\"k-means++\", max_iter=100)\n",
    "\n",
    "%time km.fit(standardized_df.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essays per cluster / Theme(s) per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = standardized_df\n",
    "output['cluster'] = km.labels_\n",
    "output['essay'] = tokenized_essays.values()\n",
    "output['title'] = tokenized_essays.keys()\n",
    "\n",
    "output['cluster'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_index = {\n",
    "                'Autobiographical, Paths to Prison': 'parent, damage, abuse, gang, alcohol, drug, neighborhood, hood, youth, pressure, fit, broken', \n",
    "                'Family': 'family, abandonment, relation, visit, partner, mother, father, sibling, child, wife, husband, abuse, support', \n",
    "                'Physical Conditions and Security': 'physical, condition, security, search, censorship, food, cold, hygiene, heat, misfunction, infestation, solitary, strip, search, fear, filth, violence, staff, abuse', \n",
    "                'Prison Culture/Community/Society': 'violence, fear, staff, sexual, crime, outcasts, racial, cellmate, gay, LGBTQ, dehumanize, uniform, pecking, order, hierarchy, solid, dirty, skin, chomo',\n",
    "                'Staff/prison Abuse of IP': 'abuse, sexual, torture, humiliation, racist, assault, antagonism, exacerbation, right, violation, food, hygiene, environment, legal, extraction, search, taunt',\n",
    "                'Personal/Intern Change/Coping': 'survival, art, reading, writing, peace, faith, prayer, meditation, practice, community, activities, hobbies, cooking, remorse, motivation, education, discipline, coping, adjustment, responsibility, god, redemption, transformation',\n",
    "                'Judicial Misconduct and Legal Remediation': 'judicial, incompetence, corruption, witness, evidence, excessive, political, jailhouse, lawyer, misconduct, unfair, pretender, plra, plea, grievance',\n",
    "                'Political and Intellectual Labor among IP': 'activism, resistence, critique, race, class, change, policies, practices, write, organize, strike, solidarity',\n",
    "                'Prison Industry/Prison as Business': 'labor, slave, condition, safety, health, profit, job, budget, tax, taxpayer, exploitation, corruption, mismanagement, nepotism',\n",
    "                'Education, Re-entry, Other Programs': 'rehabilitation, entry, education, indifference, college, vocation',\n",
    "                'Health Care': 'health, care, negligence, hostility, incompetence, indifference, death, injury, treatment, medication',\n",
    "                'Social Alienation, Indifference, Hostility': 'public, misperception, identity, stigma'\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column for each topic, assign initial value to zero\n",
    "for theme in theme_index:\n",
    "    output[theme] = 0\n",
    "    \n",
    "print(output.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "\n",
    "essays_per_cluster = {}\n",
    "for i in range(num_clusters):\n",
    "    essays_per_cluster[i] = []\n",
    "    #print(\"Cluster %d titles:\" % i, end='')\n",
    "    for title in output[output.cluster == i]['title'].values.tolist():\n",
    "        #print(' %s,' % title, end='')\n",
    "        essays_per_cluster[i].append(title)\n",
    "        \n",
    "print(\"***** Random sample essays per cluster *****\")\n",
    "print()\n",
    "\n",
    "terms_per_essays = {}\n",
    "themes_per_essays = {}\n",
    "for i in range(num_clusters):\n",
    "    ten = []\n",
    "    if len(essays_per_cluster[i]) < 10:\n",
    "        ten = essays_per_cluster[i]\n",
    "    else:\n",
    "        while len(ten) < 10:\n",
    "            essay = random.choice(essays_per_cluster[i])\n",
    "            if essay not in ten:\n",
    "                ten.append(essay)\n",
    "\n",
    "    print(\"** Cluster %d: **\" % i)\n",
    "    print()\n",
    "    context = [' '.join(tokens) for tokens in list(output[output.cluster == i].essay)]\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=50)\n",
    "    tfidf_vectorizer.fit(context)\n",
    "    \n",
    "    #terms_per_essays[i] = [term for term in tfidf_vectorizer.get_feature_names() if term not in english_stopwords + custom_stopwords]\n",
    "    terms_per_essays[i] = [term for term in tfidf_vectorizer.get_feature_names()]\n",
    "    \n",
    "    print(\"Top terms #{} : {}\".format(i, terms_per_essays[i]))\n",
    "    print()\n",
    "    \n",
    "    themes_per_essays[i] = set()\n",
    "    theme_term_count = {}\n",
    "    for term in terms_per_essays[i]:\n",
    "        for key, value in theme_index.items():\n",
    "            if term in value:\n",
    "                if key in theme_term_count:\n",
    "                    theme_term_count[key] += 1\n",
    "                else:\n",
    "                    theme_term_count[key] = 1\n",
    "                themes_per_essays[i].add(key)\n",
    "    \n",
    "    themes_per_essays[i] = [theme for theme, count in theme_term_count.items() if count > 1]\n",
    "    print(\"Dominant theme(s): {}\".format(themes_per_essays[i]))\n",
    "    print()\n",
    "    print(sorted(theme_term_count.items(), key=lambda x : x[1])[::-1])\n",
    "    \n",
    "    print()\n",
    "    print(\"Randomly selected essays:\", ten)\n",
    "#     files = [i for i in os.listdir(src) if i in ten and path.isfile(path.join(src, i))]\n",
    "#     for f in files:\n",
    "#         shutil.copy(path.join(src, f), dst + str(i))\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running LDA on each cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "val = True\n",
    "terms_per_cluster = {}\n",
    "themes_per_cluster = {}\n",
    "essays_per_cluster = {}\n",
    "\n",
    "#Apply LDA for each cluster (and for each essay in cluster)\n",
    "for i in range(num_clusters):\n",
    "    print(\"************ Cluster # {} ************\".format(i))\n",
    "    essays_in_cluster = [tokens for tokens in list(output[output.cluster == i].essay)]\n",
    "    \n",
    "    # Store titles of all essays in a given cluster.\n",
    "    essays_per_cluster[i] = list(output[output.cluster == i].title)\n",
    "    \n",
    "    dictionary = corpora.Dictionary(essays_in_cluster)\n",
    "    \n",
    "    cluster_corpus = [dictionary.doc2bow(essay) for essay in essays_in_cluster]\n",
    "    \n",
    "    lda = models.ldamodel.LdaModel(corpus=cluster_corpus, id2word=dictionary, num_topics=1, passes=10)\n",
    "    \n",
    "    term_score = {}\n",
    "    terms_per_cluster[i] = []\n",
    "    for idx, terms in lda.print_topics(0, 20):\n",
    "        #terms_per_cluster[i] = terms\n",
    "        \n",
    "        #print('Top terms: {}'.format(terms.split('+')))\n",
    "        #print()\n",
    "        #print()\n",
    "        \n",
    "        for term_with_score in terms.split('+'):\n",
    "            term = term_with_score.split('*')[1][1:-2]\n",
    "            score = term_with_score.split('*')[0]\n",
    "            \n",
    "            #print(\"term is {} with score {}\".format(term, score))\n",
    "            \n",
    "            terms_per_cluster[i].append(term)\n",
    "            term_score[term] = float(score)\n",
    "    \n",
    "    #print(\"Terms per cluster:\", terms_per_cluster)\n",
    "    #print()\n",
    "    #print(\"Terms/Scores:\", term_score)\n",
    "    #print()\n",
    "    \n",
    "    themes_per_cluster[i] = {}\n",
    "    theme_term_score = {}\n",
    "    for term in terms_per_cluster[i]:\n",
    "        for theme, defining_terms in theme_index.items():\n",
    "            if term in defining_terms:\n",
    "                if theme in theme_term_score:\n",
    "                    theme_term_score[theme] += term_score[term]\n",
    "                else:\n",
    "                    theme_term_score[theme] = term_score[term]\n",
    "                \n",
    "    themes_per_cluster[i] = sorted(theme_term_score.items(), key = lambda x : x[1])[::-1]\n",
    "    print(\"Cluster themes ranked strongest to weakest: {}\".format(themes_per_cluster[i]))\n",
    "    print()\n",
    "    \n",
    "    themes_per_essay = {}\n",
    "    terms_per_essay = {}\n",
    "    for title in essays_per_cluster[i]:\n",
    "        essay = [tokens for tokens in list(output[output.title == title].essay)]\n",
    "        dictionary = corpora.Dictionary(essay)\n",
    "        essay_corpus = [dictionary.doc2bow(e) for e in essay]\n",
    "        lda = models.ldamodel.LdaModel(corpus=essay_corpus, id2word=dictionary, num_topics=1, passes=10)\n",
    "    \n",
    "        essay_term_score = {}\n",
    "        terms_per_essay[title] = []\n",
    "        for idx, terms in lda.print_topics(i, 20):\n",
    "            \n",
    "            for term_with_score in terms.split('+'):\n",
    "                term = term_with_score.split('*')[1][1:-2]\n",
    "                score = term_with_score.split('*')[0]\n",
    "\n",
    "                terms_per_essay[title].append(term)\n",
    "                essay_term_score[term] = float(score)\n",
    "\n",
    "        themes_per_essay[title] = {}\n",
    "        essay_theme_term_score = {}\n",
    "        for term in terms_per_essay[title]:\n",
    "            for theme, defining_terms in theme_index.items():\n",
    "                if term in defining_terms:\n",
    "                    if theme in essay_term_score:\n",
    "                        essay_theme_term_score[theme] += essay_term_score[term]\n",
    "                    else:\n",
    "                        essay_theme_term_score[theme] = essay_term_score[term]\n",
    "\n",
    "        themes_per_essay[title] = sorted(essay_theme_term_score.items(), key = lambda x : x[1])[::-1]\n",
    "        \n",
    "        #### store initial scores #################################\n",
    "        for theme, score in essay_theme_term_score.items():\n",
    "            output.loc[output[output['title'] == title].index, theme] = score\n",
    "\n",
    "        \n",
    "    print(\"Total number of essays in this cluster: {}.\".format(len(essays_per_cluster[i])))\n",
    "    print()\n",
    "    \n",
    "    for title in essays_per_cluster[i][:10]:\n",
    "        print(\"Essay ({}) themes: {}\".format(title, sorted(themes_per_essay[title], key = lambda x : x[1])))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see initial scores\n",
    "output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model/Load from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'doc2vec_cluster.pkl'\n",
    "pickle.dump(km, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(v1, v2):\n",
    "    # L2 norm\n",
    "    return np.linalg.norm(v1-v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate global centroids for each topic\n",
    "theme_globcentroid = {}\n",
    "for theme in theme_index.keys():\n",
    "        \n",
    "    # get all vector columns matching theme\n",
    "    sub_df = output[output[theme] != 0].iloc[:, :100]\n",
    "\n",
    "    # number of vectors with that theme\n",
    "    n = len(sub_df)  \n",
    "\n",
    "    # mean of all vectors is centroid\n",
    "    globalcentroid = sum([sub_df.iloc[i] for i in range(n)])/n\n",
    "    theme_globcentroid[theme] = globalcentroid\n",
    "\n",
    "\n",
    "# calculate local centroids for each topic\n",
    "for cluster in range(num_clusters):\n",
    "    \n",
    "    for theme in theme_index.keys():\n",
    "        \n",
    "        # get all vector columns matching cluster and theme\n",
    "        sub_df = output[output['cluster'] == cluster]\n",
    "        sub_df = sub_df[sub_df[theme] != 0].iloc[:, :100]\n",
    "\n",
    "        # number of vectors in cluster with this theme\n",
    "        n = len(sub_df)  \n",
    "\n",
    "        # mean of all vectors is centroid with this theme\n",
    "        localcentroid = sum([sub_df.iloc[i] for i in range(n)])/n\n",
    "                \n",
    "        # find distance between current localcentroid and its corresponding globalcentoid by theme\n",
    "        d1 = distance(theme_globcentroid[theme], localcentroid)\n",
    "        \n",
    "        # find distance between each vector and its corresponding localcentroid, update rank\n",
    "        vectors = output[output['cluster'] == cluster]\n",
    "        vectors = vectors[vectors[theme] != 0].index\n",
    "        for ident in vectors:\n",
    "            loc = output.iloc[ident, :100]\n",
    "            d2 = distance(loc, localcentroid)\n",
    "            \n",
    "            # update rank - lda score * dist from v to localcentroid * dist from localcentroid to globalcentroid\n",
    "            output.at[ident, theme] = output.at[ident, theme] * d1 * d2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_we_need = output.iloc[:, 102:]\n",
    "all_we_need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
